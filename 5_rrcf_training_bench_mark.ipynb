{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410d45f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install sagemaker dill -U "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b3147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Final\n",
    "import sagemaker, dill, os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "bucket: Final[str] = sagemaker.session.Session().default_bucket()\n",
    "roke: Final[str] = sagemaker.get_execution_role()\n",
    "sess = sagemaker.session.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c5f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_base_uri = sess.upload_data('./bench_data/',key_prefix='bench_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee116ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf bench_src\n",
    "!mkdir -p bench_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6286a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile bench_src/requirements.txt\n",
    "rrcf==0.4.3\n",
    "dill==0.3.4\n",
    "matplotlib==3.5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333fc8f5",
   "metadata": {},
   "source": [
    "## シングルプロセス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9dc59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/train.py\n",
    "import rrcf\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dill\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from typing import Final\n",
    "import logging\n",
    "import sys\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# ハイパーパラメータ取得\n",
    "def get_hps():\n",
    "    logger.debug('setting hyperparameters...')\n",
    "    hps: Final[dict] = json.loads(os.environ.get('SM_HPS'))\n",
    "    # 設定されていなかった場合のデフォルト値\n",
    "    hps.setdefault('num_trees', 50)\n",
    "    hps.setdefault('shingle_size', 3)\n",
    "    hps.setdefault('tree_size', 512)\n",
    "    logger.debug('got hyperparameters...')\n",
    "    logger.info('hps is ...')\n",
    "    logger.info(hps)\n",
    "    return hps\n",
    "\n",
    "# csvファイル群を連結して DataFrame にする\n",
    "def load_csv_files(csv_dir):\n",
    "    logger.debug('loading csv...')\n",
    "#     csv_list = sorted(glob.glob(os.path.join(csv_dir,'*.csv')))\n",
    "#     df_list = [pd.read_csv(csv_file, header=None) for csv_file in csv_list]\n",
    "#     df = pd.concat(df_list, ignore_index=True)\n",
    "    csv_file = glob.glob(os.path.join(csv_dir,'*.csv'))[0]\n",
    "    df = pd.read_csv(csv_file, header=None)\n",
    "    logger.debug('loaded csv')\n",
    "    return df\n",
    "\n",
    "# 異常スコアを計算する\n",
    "# 詳細 : https://klabum.github.io/rrcf/taxi.html\n",
    "# shingle 済のデータに異常スコアを付与したDataFrameを返す\n",
    "def calc_score(df,hps):\n",
    "    # RCF 準備\n",
    "    logger.debug('preparing RCF...')\n",
    "    data = df[0].astype(float).values\n",
    "    points = rrcf.shingle(data, size=hps['shingle_size'])\n",
    "    points = np.vstack([point for point in points])\n",
    "    n = points.shape[0]\n",
    "    sample_size_range = (n // hps['tree_size'], hps['tree_size'])\n",
    "    logger.debug('prepared RCF')\n",
    "    \n",
    "    # RCF を生成\n",
    "    logger.debug('generating RCF...')\n",
    "    forest = []\n",
    "    while len(forest) < hps['num_trees']:\n",
    "        ixs = np.random.choice(n, size=sample_size_range,\n",
    "                               replace=False)\n",
    "        trees = [rrcf.RCTree(points[ix], index_labels=ix) for ix in ixs]\n",
    "        forest.extend(trees)\n",
    "    logger.debug('generated RCF')\n",
    "    \n",
    "    # 異常スコア算出\n",
    "    logger.debug('calculating score...')\n",
    "    avg_codisp = pd.Series(0.0, index=np.arange(n))\n",
    "    index = np.zeros(n)\n",
    "    for tree in forest:\n",
    "        codisp = pd.Series({leaf : tree.codisp(leaf) for leaf in tree.leaves})\n",
    "        avg_codisp[codisp.index] += codisp\n",
    "        np.add.at(index, codisp.index.values, 1)\n",
    "    avg_codisp /= index\n",
    "    logger.debug('calculated score')\n",
    "    \n",
    "    # result の整理\n",
    "    logger.debug('organizing score...')\n",
    "    columns = [i for i in range(points.shape[1])]\n",
    "    result_df = pd.DataFrame(points, columns=columns, dtype='float')\n",
    "    result_df['score'] = pd.Series(avg_codisp)\n",
    "    result_df['scaled_score'] = result_df['score']/result_df['score'].max()\n",
    "    \n",
    "    logger.debug('organized score')\n",
    "    return result_df, forest\n",
    "\n",
    "# 異常判定\n",
    "def calc_threshold(df):\n",
    "    logger.debug('calculating calc_threshold...')\n",
    "    df['zscore'] = stats.zscore(df['score'])\n",
    "    df['anomaly'] = df['zscore'].apply(lambda x: True if x>3 else False)\n",
    "    return df\n",
    "\n",
    "# グラフの描画\n",
    "def draw_graph(result_df):\n",
    "    logger.debug('drawing graph...')\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    ax1 = fig.add_subplot(3,1,1)\n",
    "    for col in result_df.columns.values:\n",
    "        if type(col)==int:\n",
    "            ax1.plot(result_df[col])\n",
    "        else:\n",
    "            break\n",
    "    ax2 = fig.add_subplot(3,1,2)\n",
    "    ax2.plot(result_df['score'])\n",
    "    ax3 = fig.add_subplot(3,1,3)\n",
    "    ax3.plot(result_df['anomaly'])\n",
    "    logger.debug('drawn graph')\n",
    "    return fig\n",
    "\n",
    "def main(model_base_dir, target_dir_list, hps):\n",
    "    for target_dir in target_dir_list:\n",
    "        logger.info(f\"target : {target_dir.replace('/opt/ml/input/data/training/','')}\")\n",
    "        \n",
    "        # 生成物の出力先設定\n",
    "        artifact_dir = os.path.join(model_base_dir,target_dir.replace('/opt/ml/input/data/training/',''))\n",
    "        os.makedirs(artifact_dir)\n",
    "#         model_path = os.path.join(artifact_dir,'model.dill')\n",
    "#         graph_path = os.path.join(artifact_dir,'graph.png')\n",
    "        csv_path = os.path.join(artifact_dir,'result.csv')\n",
    "        \n",
    "        # 使用するデータをロードして１つの DataFrame にまとめる\n",
    "        df = load_csv_files(target_dir)\n",
    "        \n",
    "        # スコアの算出と算出に使用した shingle 済データと、RCF を作成\n",
    "        result_df, forest = calc_score(df, hps)\n",
    "        \n",
    "        # しきい値計算と判定\n",
    "        result_df = calc_threshold(result_df)\n",
    "        \n",
    "        # 結果 DF の出力\n",
    "        result_df.to_csv(csv_path,index=False)\n",
    "        \n",
    "#         # RCF の出力\n",
    "#         with open(model_path,'wb') as f:\n",
    "#             dill.dump(forest, f)\n",
    "        \n",
    "#         # shingle 済データとスコアのグラフ描画と出力\n",
    "#         fig = draw_graph(result_df)\n",
    "#         fig.savefig(graph_path,dpi=300)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logger.info('exec start...')\n",
    "    hps = get_hps()\n",
    "    input_dir: Final[str] = os.environ.get('SM_CHANNEL_TRAINING')\n",
    "    model_base_dir: Final[str] = os.environ.get('SM_MODEL_DIR')\n",
    "    target_dir_list: Final[list] = glob.glob(os.path.join(input_dir,'*'))\n",
    "    main(model_base_dir, target_dir_list, hps)\n",
    "    logger.info('completed')\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607872a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "estimator = SKLearn(\n",
    "    base_job_name='rrcf-single-process',\n",
    "    entry_point='train.py',\n",
    "    source_dir = './src/',\n",
    "    py_version='py3', \n",
    "    framework_version='1.0-1',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.xlarge',\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    hyperparameters={\n",
    "        'num_trees': 128,\n",
    "        'shingle_size': 10,\n",
    "        'tree_size': 1024,\n",
    "    },\n",
    "    volume_size=200\n",
    ")\n",
    "estimator.fit(\n",
    "    s3_base_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee999e",
   "metadata": {},
   "source": [
    "## マルチプロセス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26039603",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf bench_multi_src\n",
    "!mkdir -p bench_multi_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile bench_multi_src/requirements.txt\n",
    "rrcf==0.4.3\n",
    "dill==0.3.4\n",
    "matplotlib==3.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile bench_multi_src/train_multi_processing.py\n",
    "import rrcf\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dill\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from typing import Final\n",
    "import logging\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "input_dir: Final[str] = os.environ.get('SM_CHANNEL_TRAINING')\n",
    "model_base_dir: Final[str] = os.environ.get('SM_MODEL_DIR')\n",
    "\n",
    "logger.debug('setting hyperparameters...')\n",
    "hps: Final[dict] = json.loads(os.environ.get('SM_HPS'))\n",
    "# 設定されていなかった場合のデフォルト値\n",
    "hps.setdefault('num_trees', 50)\n",
    "hps.setdefault('shingle_size', 3)\n",
    "hps.setdefault('tree_size', 512)\n",
    "hps.setdefault('process_num',1)\n",
    "logger.debug('got hyperparameters...')\n",
    "logger.info('hps is ...')\n",
    "logger.info(hps)\n",
    "target_dir_list: Final[list] = glob.glob(os.path.join(input_dir,'*'))\n",
    "\n",
    "# csvファイル群を連結して DataFrame にする\n",
    "def load_csv_files(csv_dir):\n",
    "    logger.debug('loading csv...')\n",
    "#     csv_list = sorted(glob.glob(os.path.join(csv_dir,'*.csv')))\n",
    "#     df_list = [pd.read_csv(csv_file, header=None) for csv_file in csv_list]\n",
    "#     df = pd.concat(df_list, ignore_index=True)\n",
    "    csv_file = glob.glob(os.path.join(csv_dir,'*.csv'))[0]\n",
    "    df = pd.read_csv(csv_file, header=None)\n",
    "    logger.debug('loaded csv')\n",
    "    return df\n",
    "\n",
    "# 異常スコアを計算する\n",
    "# 詳細 : https://klabum.github.io/rrcf/taxi.html\n",
    "# shingle 済のデータに異常スコアを付与したDataFrameを返す\n",
    "def calc_score(df,hps):\n",
    "    # RCF 準備\n",
    "    logger.debug('preparing RCF...')\n",
    "    data = df[0].astype(float).values\n",
    "    points = rrcf.shingle(data, size=hps['shingle_size'])\n",
    "    points = np.vstack([point for point in points])\n",
    "    n = points.shape[0]\n",
    "    sample_size_range = (n // hps['tree_size'], hps['tree_size'])\n",
    "    logger.debug('prepared RCF')\n",
    "    \n",
    "    # RCF を生成\n",
    "    logger.debug('generating RCF...')\n",
    "    forest = []\n",
    "    while len(forest) < hps['num_trees']:\n",
    "        ixs = np.random.choice(n, size=sample_size_range,\n",
    "                               replace=False)\n",
    "        trees = [rrcf.RCTree(points[ix], index_labels=ix) for ix in ixs]\n",
    "        forest.extend(trees)\n",
    "    logger.debug('generated RCF')\n",
    "    \n",
    "    # 異常スコア算出\n",
    "    logger.debug('calculating score...')\n",
    "    avg_codisp = pd.Series(0.0, index=np.arange(n))\n",
    "    index = np.zeros(n)\n",
    "    for tree in forest:\n",
    "        codisp = pd.Series({leaf : tree.codisp(leaf) for leaf in tree.leaves})\n",
    "        avg_codisp[codisp.index] += codisp\n",
    "        np.add.at(index, codisp.index.values, 1)\n",
    "    avg_codisp /= index\n",
    "    logger.debug('calculated score')\n",
    "    \n",
    "    # result の整理\n",
    "    logger.debug('organizing score...')\n",
    "    columns = [i for i in range(points.shape[1])]\n",
    "    result_df = pd.DataFrame(points, columns=columns, dtype='float')\n",
    "    result_df['score'] = pd.Series(avg_codisp)\n",
    "    result_df['scaled_score'] = result_df['score']/result_df['score'].max()\n",
    "    \n",
    "    logger.debug('organized score')\n",
    "    return result_df, forest\n",
    "\n",
    "# 異常判定\n",
    "def calc_threshold(df):\n",
    "    logger.debug('calculating calc_threshold...')\n",
    "    df['zscore'] = stats.zscore(df['score'])\n",
    "    df['anomaly'] = df['zscore'].apply(lambda x: True if x>3 else False)\n",
    "    return df\n",
    "\n",
    "# グラフの描画\n",
    "def draw_graph(result_df):\n",
    "    logger.debug('drawing graph...')\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    ax1 = fig.add_subplot(3,1,1)\n",
    "    for col in result_df.columns.values:\n",
    "        if type(col)==int:\n",
    "            ax1.plot(result_df[col])\n",
    "        else:\n",
    "            break\n",
    "    ax2 = fig.add_subplot(3,1,2)\n",
    "    ax2.plot(result_df['score'])\n",
    "    ax3 = fig.add_subplot(3,1,3)\n",
    "    ax3.plot(result_df['anomaly'])\n",
    "    logger.debug('drawn graph')\n",
    "    return fig\n",
    "\n",
    "def main(target_dir):\n",
    "    logger.info(f\"target : {target_dir.replace('/opt/ml/input/data/training/','')}\")\n",
    "    # 生成物の出力先設定\n",
    "    artifact_dir = os.path.join(model_base_dir,target_dir.replace('/opt/ml/input/data/training/',''))\n",
    "    os.makedirs(artifact_dir)\n",
    "#         model_path = os.path.join(artifact_dir,'model.dill')\n",
    "#         graph_path = os.path.join(artifact_dir,'graph.png')\n",
    "    csv_path = os.path.join(artifact_dir,'result.csv')\n",
    "\n",
    "    # 使用するデータをロードして１つの DataFrame にまとめる\n",
    "    df = load_csv_files(target_dir)\n",
    "\n",
    "    # スコアの算出と算出に使用した shingle 済データと、RCF を作成\n",
    "    result_df, forest = calc_score(df, hps)\n",
    "\n",
    "    # しきい値計算と判定\n",
    "    result_df = calc_threshold(result_df)\n",
    "\n",
    "    # 結果 DF の出力\n",
    "    result_df.to_csv(csv_path,index=False)\n",
    "        \n",
    "#         # RCF の出力\n",
    "#         with open(model_path,'wb') as f:\n",
    "#             dill.dump(forest, f)\n",
    "        \n",
    "#         # shingle 済データとスコアのグラフ描画と出力\n",
    "#         fig = draw_graph(result_df)\n",
    "#         fig.savefig(graph_path,dpi=300)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logger.info('exec start...')\n",
    "    with Pool(processes=hps['process_num']) as pool:\n",
    "        pool.map(main,target_dir_list)\n",
    "    logger.info('completed')\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f4fb05",
   "metadata": {},
   "source": [
    "### c5.xlarge 3 processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dfd620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "estimator = SKLearn(\n",
    "    base_job_name='rrcf-3-processes',\n",
    "    entry_point='train_multi_processing.py',\n",
    "    source_dir = './bench_multi_src/',\n",
    "    py_version='py3', \n",
    "    framework_version='1.0-1',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.xlarge',\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    hyperparameters={\n",
    "        'num_trees': 128,\n",
    "        'shingle_size': 10,\n",
    "        'tree_size': 1024,\n",
    "        'process_num':3\n",
    "    },\n",
    "    volume_size=200\n",
    ")\n",
    "estimator.fit(\n",
    "    s3_base_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b141f061",
   "metadata": {},
   "source": [
    "## c5.xlarge 4 processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba37c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "estimator = SKLearn(\n",
    "    base_job_name='rrcf-4-processes',\n",
    "    entry_point='train_multi_processing.py',\n",
    "    source_dir = './bench_multi_src/',\n",
    "    py_version='py3', \n",
    "    framework_version='1.0-1',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.xlarge',\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    hyperparameters={\n",
    "        'num_trees': 128,\n",
    "        'shingle_size': 10,\n",
    "        'tree_size': 1024,\n",
    "        'process_num':4\n",
    "    },\n",
    "    volume_size=200\n",
    ")\n",
    "estimator.fit(\n",
    "    s3_base_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a831b8fa",
   "metadata": {},
   "source": [
    "### c5.4xlarge 15 processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "estimator = SKLearn(\n",
    "    base_job_name='rrcf-15-processes',\n",
    "    entry_point='train_multi_processing.py',\n",
    "    source_dir = './bench_multi_src/',\n",
    "    py_version='py3', \n",
    "    framework_version='1.0-1',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.4xlarge',\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    hyperparameters={\n",
    "        'num_trees': 128,\n",
    "        'shingle_size': 10,\n",
    "        'tree_size': 1024,\n",
    "        'process_num':15\n",
    "    },\n",
    "    volume_size=200\n",
    ")\n",
    "estimator.fit(\n",
    "    s3_base_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88cc3e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "estimator = SKLearn(\n",
    "    base_job_name='rrcf-16-processes',\n",
    "    entry_point='train_multi_processing.py',\n",
    "    source_dir = './bench_multi_src/',\n",
    "    py_version='py3', \n",
    "    framework_version='1.0-1',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.4xlarge',\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    hyperparameters={\n",
    "        'num_trees': 128,\n",
    "        'shingle_size': 10,\n",
    "        'tree_size': 1024,\n",
    "        'process_num':16\n",
    "    },\n",
    "    volume_size=200\n",
    ")\n",
    "estimator.fit(\n",
    "    s3_base_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ec4e8",
   "metadata": {},
   "source": [
    "### c5.9xlarge 35 parallels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd2516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "estimator = SKLearn(\n",
    "    base_job_name='rrcf-35-processes',\n",
    "    entry_point='train_multi_processing.py',\n",
    "    source_dir = './bench_multi_src/',\n",
    "    py_version='py3', \n",
    "    framework_version='1.0-1',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.9xlarge',\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    hyperparameters={\n",
    "        'num_trees': 128,\n",
    "        'shingle_size': 10,\n",
    "        'tree_size': 1024,\n",
    "        'process_num':35\n",
    "    },\n",
    "    volume_size=200\n",
    ")\n",
    "estimator.fit(\n",
    "    s3_base_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11ace9b",
   "metadata": {},
   "source": [
    "### c5.9xlarge 36 parallels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f45d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "estimator = SKLearn(\n",
    "    base_job_name='rrcf-36-processes',\n",
    "    entry_point='train_multi_processing.py',\n",
    "    source_dir = './bench_multi_src/',\n",
    "    py_version='py3', \n",
    "    framework_version='1.0-1',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.9xlarge',\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    hyperparameters={\n",
    "        'num_trees': 128,\n",
    "        'shingle_size': 10,\n",
    "        'tree_size': 1024,\n",
    "        'process_num':36\n",
    "    },\n",
    "    volume_size=200\n",
    ")\n",
    "estimator.fit(\n",
    "    s3_base_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588da5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "estimator = SKLearn(\n",
    "    base_job_name='rrcf-71-processes',\n",
    "    entry_point='train_multi_processing.py',\n",
    "    source_dir = './bench_multi_src/',\n",
    "    py_version='py3', \n",
    "    framework_version='1.0-1',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.18xlarge',\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    hyperparameters={\n",
    "        'num_trees': 128,\n",
    "        'shingle_size': 10,\n",
    "        'tree_size': 1024,\n",
    "        'process_num':71\n",
    "    },\n",
    "    volume_size=200\n",
    ")\n",
    "estimator.fit(\n",
    "    s3_base_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa6adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
